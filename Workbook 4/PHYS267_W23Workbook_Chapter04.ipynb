{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb5de88",
   "metadata": {},
   "source": [
    "# PHYS 267 - Chapter 4<br><font color='blue'>Introduction to Probability</font>\n",
    "###### Last Updated: Jan 9, 2023 by Dr. Brenda Lee\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581a3027",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">4.1 Chapter Overview</font>\n",
    "\n",
    "We now start our journey into probability and statistics. The two of these combined allow us to discuss situations in nature that cannot be fully described or predicted with complete certainty. In classical physics, unlike quantum mechanics, we hold the belief that natural events are *deterministic*, which means that one event causes another event. This means that if we know the initial conditions of a system and the physical laws that govern that system, we can quickly predict its condition at all future times; or work backwards to know what happened in the past. \n",
    "\n",
    "But is this always true for all cases? Absolutely not. Real life is full of uncertainty. Here's a quick example: if I point to a box full of gaseous molecules and ask you to pick a molecule and tell me its exact velocity...would you be able to do it? Probably not, but you would be able to say which values are likely and which values are unlikely. And that term, \"*likely*\" needs to be further defined through our discussions in probability.\n",
    "\n",
    "Let's first see where unpredictability comes from:\n",
    "- Incomplete Knowledge: sometimes, we may not know everything there is to know about a system to make an accurate prediction\n",
    "- Large Numbers: When there are a large number of things, it is more difficult to predict the action of one within many\n",
    "- Sensitivity to Initial Conditions: Sometimes you may have two identical systems that evolve differently due to different starting conditions; they may converge to reduce differences between systems or they may diverge to cause dynamical chaos between systems\n",
    "- Open Systems: Although as physicists, we like to think of everything in an ideal way; in real life, things are very far away from that. Sometimes, a closed system may have cracks in it that allow external factors to affect it. In such cases, those external factors can change the behavior of components within the supposedly closed system, making things more unpredictable\n",
    "\n",
    "Amidst all this, we can still try to predict the future. So we define **probability** as a concept related to either one of two things:\n",
    "1. The **frequency** with which unpredictable events occur - the \"frequentist approach\"\n",
    "2. The **degree of belief** that some hypothesis is correct - the \"Bayesian approach\"\n",
    "\n",
    "Both these types of analyses are critical to a thorough understanding of probability theory. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">ðŸ’Ž<b>Chapter Objectives</b>:<br>\n",
    "    <ol>\n",
    "        <li>Learn different ways of describing and calculating probability</li>\n",
    "        <li>Discuss frequentist approach to probability via counting methods and various rules</li>\n",
    "        <li>Discuss Baye's Rule and the Law of Total Probability</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96565f1a",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">4.2 Frequentist Approach to Probability</font>\n",
    "\n",
    "Prior to discussing frequentist and Bayesian approaches to probability, let's go through some definitions. We start off with looking at events and a sample space.\n",
    "\n",
    "#### 4.2.1 Events and the Sample Space\n",
    "\n",
    "When we collect data, it must come from some method of data collection called an **experiment**. When an experiment is performed one time, what we observe is an outcome that is called a **simple event**, commonly denoted as $E$ with a subscript (ie. 1st event is called $E_1$). If you roll a dice 6 times, you will have 6 simple events, labelled from $E_1$ to $E_6$. A collection of all simple events within an experiment is called an **event**. And we call the set of all simple events the **sample space $S$**.\n",
    "\n",
    "To help visualize the sample space, we can use a tree digram where each successive level of branching on the tree corresponds to a step required to generate the final outcome.\n",
    "\n",
    "Sometimes, there are events that cannot occur if another event has taken place. We call these **mutually exclusive** events. Based on the simple events above, we can say that each one of those are mutually exclusive when done once and only one face can show up on the single dice. If you have two dice, then for each event, the events are no longer mutually exclusive as you can have the same value pop up on each dice.\n",
    "\n",
    "#### 4.2.2 Calculating Probabilities Using Simple Events\n",
    "\n",
    "The probability of an event $A$ taking place is a measure of our belief that the event $A$ will occur. Starting from relative frequency, given as:\n",
    "\n",
    "$$\\text{relative frequency} = \\frac{frequency}{n}$$\n",
    "\n",
    "We know that as $n$ increases to $\\infty$, we will arrive at the total population. We define this as the **probability of event $A$**:\n",
    "\n",
    "$$P(A) = \\lim_{n \\to \\infty}\\frac{frequency}{n}$$\n",
    "\n",
    "Needless to say, if you roll a 6-sided die one time, you would have a 1/6 chance of getting any of the values on the die.\n",
    "\n",
    "Things to Note:\n",
    "- Each probability must lie between 0 and 1\n",
    "- The sume of the probabilities for all simple events in $S$ will equal to 1\n",
    "\n",
    "But, what happens if we are looking at an event with multiple dice? The **probability of event $A$** is also equal to the sum of the probabilities of the simple events contained in $A$. This is different than tossing one die, we are tossing two dice at the same time and trying to find the probability of 1 simple event happening. In other words, what are the chances of us getting a 4 with either of the dice? In this case, we would have a 1/6 chance for each dice, and two would give us twice the 1/6 chance for a total of 2/6 = 1/3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fcad40",
   "metadata": {},
   "source": [
    "#### 4.2.3 Counting Rules for Probability\n",
    "\n",
    "There are ways to help streamline our calculation of probability for different experiments. First, we can say that if an experiment involves a large number $n$ of simple events and all simple events are equally likely, then each simple event has a probability of $1/N$ and the probability of an event $A$ can be calculated as follows, where $n_A$ is the number of simple events that result in event $A$:\n",
    "\n",
    "$$P(A) = \\frac{n_A}{N}$$\n",
    "\n",
    "There are some additional rules we can use after this.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>The $mn$ Rule for Calculating Total Number of Simple Events</b>: If the first set of values can be achieved in $m$ ways and for each of these ways, additional values can be achieved in $n$ ways, then there arre $mn$ ways to achieve a unique value.</p>\n",
    "</div>\n",
    "\n",
    "**Example 1**: Two dice are tossed. How many simple events are in sample space $S$?\n",
    "\n",
    "*Solution*: The 1st die can present 1 of 6 values, and so can the 2nd die. With $m=6$ and $n=6$, we have $mn=36$ simple events in our sample space.\n",
    "\n",
    "**Example 2**: There are 5 different tickets in a hat. 2 tickets are selected from the hat, one at a time. How many simple events are in the sample space?\n",
    "\n",
    "*Solution*: The 1st ticket has is 1 out of 5 possibilities so $m=5$, and the 2nd ticket is 1 out of 4 possibilites so $n=4$. This means $mn = 5 \\times 4 = 20$ simple events in the sample space.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>The Extended $mn$ Rule for Simple Events</b>: If we are performing an experiment in $k$ number of stages, with $n_1$ ways to accomplish the first stage, $n_2$ ways to accomplish the second stage, and so on until the $k$th stage, then the number of ways to accomplish the experiment is given as $n_1 n_2 n_3 \\cdots n_k$</p>\n",
    "</div>\n",
    "\n",
    "**Example 3**: Let's say you want to toss three coins, one at a time. What is the total sample space?\n",
    "\n",
    "*Solution*: We have one of two possibilities for each coin toss, so $S = 2 \\times 2 \\times 2 = 8$\n",
    "\n",
    "Let's now move on to another useful counting rule that takes into account the **ordering** or **permutation** of values. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Counting Rule for Permutations</b>: The number of ways we can arrange $n$ distinct objects, taking them $k$ at a time, is given by:</p>\n",
    "    <p>$$P_k^n = \\frac{n!}{(n-k)!}$$</p>\n",
    "    <p>where $n! = n(n-1)(n-2) \\cdots (3)(2)(1)$ with $0!=1$</p>\n",
    "    <p>Note that $n!$ gives us the total number of ways to arrange an entire set of $n$ distinct items</p>\n",
    "</div>\n",
    "\n",
    "**Example 4**: You are  a co-op students waiting for an interview. You are given a ticket (out of a total of 50 tickets) that is distributed in the order it is drawn, and a total of three tickets are drawn for you and your peers to determine interview order. How many simple events are there?\n",
    "\n",
    "*Solution*: The tickets are drawn in a specific order, so order does matter. This means that we have to approach the question using *permutations*, and we get:\n",
    "\n",
    "$$P_3^{50} = \\frac{50!}{47!} = 117,600$$\n",
    "\n",
    "**Example 5**: Your lab equipment has to be assembled and consists of 6 parts. The great thing about this instrument that you have purchased is that it can be assembled in any order, but it may take a different amount of time. You try to test the order of assembly to see which way is the fastest. How many tests would you have to perform?\n",
    "\n",
    "*Solution*: Although the order of assembly doesn't matter, your test is trying to figure out which order is better. So in this case, yes, order does matter again. So we now have:\n",
    "\n",
    "$$P_6^6 = \\frac{6!}{0!} = 720$$\n",
    "\n",
    "Coming from that question, we also realize that order really doesn't matter sometimes. And in such cases when order does not matter, we look at **combinations**, and there is a counting rule for that too!\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Counting Rule for Combinations</b>: The number of distinct combinations of $n$ distinct objects that can be formed, taking them $k$ at a time, is:</p>\n",
    "    <p>$$C_k^n = \\frac{n!}{k!(n-k)!}$$</p>\n",
    "</div>\n",
    "\n",
    "Just looking at these equations, however, we do see a relationship between permutations and combinations given mathematically as:\n",
    "\n",
    "$$C_k^n = \\frac{P_k^n}{k!}$$\n",
    "\n",
    "**Example 6**: Five manufacturers produce a certain electronic device, whose quality varies from manufacturer to manufacturer. If you were to select three manufacturers at random, what is the chance that the selection would contain exactly two of the best three?\n",
    "\n",
    "*Solution*: We know that of the 5 products, 3 are considered the \"best\" and the 2 remaining are \"normal\". That means that we want to find the chance that we get any one of the 3 from a total of 5, or \"5 choose 3\" to get:\n",
    "\n",
    "$$C_3^5 = \\frac{5!}{3!2!} = 10$$\n",
    "\n",
    "But, we're not done yet! We want to find the chance that our selection will contain *exactly 2* of the best three. In the first go, we have a selection of 2 from 3 best products:\n",
    "\n",
    "$$C_2^3 = \\frac{3!}{2!1!} = 3$$\n",
    "\n",
    "After the first run, we've lost one of our 3 best products and now we have 2 so the chances of getting another best product are:\n",
    "\n",
    "$$C_1^2 = \\frac{2!}{1!1!} = 2$$\n",
    "\n",
    "If we apply the $mn$ rule, we know that the sample space is $S = (3)(2) = 6$ and we can say that the probability of these 6 events happening in a total of 10 would be:\n",
    "\n",
    "$$P(A) = \\frac{S}{N} = 6/10 = 0.6$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da7004",
   "metadata": {},
   "source": [
    "#### 4.2.4 Event Relations and Probability Rules\n",
    "\n",
    "When looking at events, we may sometimes be looking at a combination of events that take place. To examine this, we look at two events $A$ and $B$ defined on the sample space $S$. There are three important relationships that can occur between events:\n",
    "- **Union** of events where either $A$ or $B$ or both occur, denoted by $A\\cup B$\n",
    "- **Intersection** of events where both $A$ and $B$ occur, denoted by $A\\cap B$\n",
    "- **Complement** of an event $A$ where $A$ does not occur, denoted by $A^C$\n",
    "\n",
    "With this in mind, how can we calculate probabilities for these event relations?\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Addition Rule</b>: Given two events $A$ and $B$, the probability of their <b>union</b> is given by:</p>\n",
    "    <p>$$P(A\\cup B) = P(A) + P(B) - P(A\\cap B)$$</p>\n",
    "    <p>If the two events are <b>mutually exclusive</b>, then we have:</p>\n",
    "    <p>$$P(A\\cup B) = P(A) + P(B)$$</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>Rule for Complements</b>: The probability of the <b>complement of event $A$</b> is:</p>\n",
    "    <p>$$P(A^C) = 1 - P(A)$$</p>\n",
    "</div>\n",
    "\n",
    "There is a rule to calculate the probability of the intersection of several events, but that requires us to understand the notion of independence first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f301630",
   "metadata": {},
   "source": [
    "#### 4.2.5 Independence and the Multiplication Rule\n",
    "\n",
    "An important statistical concept we will have to understand is **independent event** vs. **dependent event**. Two events, $A$ and $B$ are said to be **independent** if and only if the probability of event $B$ is not influenced or changed by the occurrence of event $A$, and vice versa. In other words, each event has its own standalone probability.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>General Multiplication Rule</b>: The probability that <i>both</i> $A$ and $B$ occur when an experiment is performed is given by:</p>\n",
    "    <p>$$P(A\\cap B) = P(A)P(B|A)$$</p>\n",
    "    <p>or:</p>\n",
    "    <p><p>$$P(A\\cap B) = P(B)P(A|B)$$</p>\n",
    "</div>\n",
    "\n",
    "Note that these equations, when rearranged, will give you the equations for **conditional probabilities**, which are denoted as $P(A|B)$ and $P(B|A)$, where $P(A)$ and $P(B)$ must not be equal to zero. \n",
    "\n",
    "More importantly, we can equate the two equations from the General Multiplication Rule to get **Bayes's Theorem*!\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <p><b>Bayes Theorem</b>: This describes the probability of an event based on prior knowledge of conditions that could be related to the event:</p>\n",
    "    <p>$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$</p>\n",
    "    <p>This is quite important for statistical inference, but we will cover that in a much later chapter.</p>\n",
    "</div>\n",
    "\n",
    "Moving forward, we have easier ways of representing this information. The following two sections are key to calculating probability for independent events.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p><b>Multiplication Rule for Independent Events</b>: If two or more events are independent, the probability that all of the events occur is given by (example for events $A, B, C$):</p>\n",
    "    <p>$$P(A\\cap B \\cap C) = P(A)P(B)P(C)$$</p>\n",
    "    <p>In other words, you multiply the individual probabilites to get the total probability.</p>\n",
    "</div>\n",
    "\n",
    "But, how do we **check for independence**? We know that two events are **independent** if and only if either:\n",
    "- $P(A\\cap B) = P(A)P(B)$, or\n",
    "- $P(B|A) = P(B)$\n",
    "\n",
    "Otherwise, the events are considered **dependent**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912590b2",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">4.3 Bayesian Approach to Probability</font>\n",
    "\n",
    "Now, it's time to look at another side of probability: the degree of belief of a hypothesis. Let's take a look at an example to gauge the difference between a Bayesian and frequentist approach. We will compare the probability of getting heads or tails for a coin toss.\n",
    "\n",
    "*What would a frequentist say?* They would argue that if the probability of heads is 1/2, then it is highly probable that approximately the same number of heads and tails will be achieved. In other words, the chances of heads or tails is 50/50. This is a very common method of thinking we have all seen before.\n",
    "\n",
    "*What would a Bayesian say?* Given that they have a subjectivist point of view, the Bayesian would argue that the probability of heads being 1/2 means that one can safely guess that the probability of getting heads or tails is 1/2 but that further study is required. \n",
    "\n",
    "This type of Bayesian approach is very compatible with experiments and testing hypothesis. So we start with defining the **hypothesis**, the assertion that some statement is true. For example, \"I will pass this test today\", or \"the velocity of this particle is less than 3 m/s\". If this were a perfect world, we would be able to assign boolean values to the hypothesis in which case 1 would mean true, and 0 would mean false for the hypothesis we have. But, our world is far from perfect, and so we must move away from definite statements about truth and falsehood. We move towards expressing degrees of belief in hypotheses, depending on the evidence we have. We now move away from those boolean values and introduce a sliding scale of \"belief\" from 0 to 1, with 0 being definitely untrue, and 1 being definitely true - we call this \"belief\" the **plausibility** of a hypothesis.\n",
    "\n",
    "So, how can we calculate such plausibilities or credibilities of a hypothesis? We simply use our previous equations from Chapter 4.2, and make a few slight changes in terminology.\n",
    "- Let $S$ be a conjecture or hypothesis\n",
    "- Let $A$ by the data\n",
    "- This means that we can use Bayes' formula for conditional probability:\n",
    "$$P(S|A) = \\frac{P(A|S)P(S)}{P(A)}$$\n",
    "\n",
    "And we define the terms as follows:\n",
    "- $P(S)$ is the *prior probability* of $S$, or the probability that $S$ is correct before $A$ data was observed\n",
    "- $P(A|S)$ is the *conditional probability* or **likelihood** of observed data $A$ given that the conjecture $S$ is true\n",
    "- $P(A)$ is the *marginal probability* of data set $A$\n",
    "- $P(S|A)$ is called the *posterior probability*, which is the probability that the hypothesis is true, given the data and the previous belief about the hypothesis\n",
    "\n",
    "With this general overview of equations and concepts in frequentist and Bayesian probability, we can now move forward to our next chapter in analyzing probability distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242c224",
   "metadata": {},
   "source": [
    "### <font color=\"green\">4.4 Practice Problems</font>\n",
    "\n",
    "Try to answer these problems yourself before the live lectures and tutorials. Feel free to connect with your peers on Discord or on campus if you prefer to work together. If you are struggling with them, we will cover them during live sessions.\n",
    "\n",
    "**Please note that for this chapter, you will NOT be expected to code in Python, but you MAY use Python to code up the solutions if you prefer. The content in this chapter is purely conceptual and the mathematics can be done by hand or by Python**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ddcb78",
   "metadata": {},
   "source": [
    "#### Problem 4A\n",
    "\n",
    "A hat contains four coins: a nickel, a dime, a quarter and a loonie. Three coins are randomly selected from the hat.\n",
    "1. List the simple events in $S$\n",
    "2. What is the probability that the selection will contain the loonie?\n",
    "3. What is the probability that the total amount drawn will equal $1.10 or more?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d302d1",
   "metadata": {},
   "source": [
    "#### Problem 4A - Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69abfd4f",
   "metadata": {},
   "source": [
    "1. {Nickle,Dime,quarter; Nickle,Dime,Loonie; Nickle,Quarter,loonie; Dime,Quarter,loonie} therefore 4\n",
    "2. 3/4 since only 3 haveloonie\n",
    "3. N = 5 cents; D = 10 cents; Quarter = 25 cents; Loonie = 100 cents\n",
    "    5+10+25 = 40; 5+10+100 = 115; 5+25+100 = 130; 10+25+100 = 135\n",
    "    3/4 are 1.10 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67741725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2012ea66",
   "metadata": {},
   "source": [
    "#### Problem 4B\n",
    "\n",
    "Five cards are selected from a 52-card deck for a poker hand. \n",
    "1. How many simple events are in the sample space?\n",
    "2. A royal flush is a hand that contains the A, K, Q, J, and 10, all in the same suit. How many ways are there to get a royal flush?\n",
    "3. What is the probability of being dealt a royal flush?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b75853",
   "metadata": {},
   "source": [
    "#### Problem 4B - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ccfd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The simple events for 1 are 2598960\n",
      "3. the probability of dealing a royal flush is 1.5390771693292702e-06\n"
     ]
    }
   ],
   "source": [
    "#1. We can do nCr(52,5)\n",
    "from math import comb\n",
    "print(\"The simple events for 1 are\", comb(52,5))\n",
    "\n",
    "#2. only 4 ways to get a Royal flush since they all need to be the same suit\n",
    "\n",
    "print(\"3. the probability of dealing a royal flush is\", 4/(comb(52,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12747de",
   "metadata": {},
   "source": [
    "#### Problem 4C\n",
    "\n",
    "Explain the differences between **mutually exclusive** and **independent events**, with relevant equations for each. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd1ba2",
   "metadata": {},
   "source": [
    "#### Problem 4C - Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef9f3fdd",
   "metadata": {},
   "source": [
    "Mutually exclusive events are events that cannot happen at the same time, for instance we cannot roll the 2 and 3 in a single roll of die, this means P(A and B) = P(A)*P(B) = 0 ; P(A U B) = P(A)+P(B)\n",
    "\n",
    "Independent events happen \"independtly\" or rather don't influence each other simultaneously, for example drawing a card and rolling a die.     \n",
    "P(A and B) = P(A)*P(B) ;  P(A U B) = P(A)+P(B) - P(A)*P(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a36fe",
   "metadata": {},
   "source": [
    "#### Problem 4D\n",
    "\n",
    "A university student frequents one of two coffee houses on campus: Starbucks 30% of the time and Tim Hortons 70% of the time. Regardless of where they go, they buy a decaffeinated coffee on 60% of their visits.\n",
    "1. The next time they go into a coffee house on campus, what is the probability that they go to Tim Hortons and orders a decaffeinated coffee?\n",
    "2. Are the two events in Question 1 independent? Explain.\n",
    "3. If they go into a coffee house and order a decaffeinated coffee, what is the probability that they are at a Starbucks?\n",
    "4. What is the probability that they go to Tim Hortons or orders a decaffeinated coffee or both?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a17f9",
   "metadata": {},
   "source": [
    "#### Problem 4D - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d5c5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. P(Tim)*P(Decafe|Tim) = 0.7*0.6 = 0.42\n"
     ]
    }
   ],
   "source": [
    "print(\"1. P(Tim)*P(Decafe|Tim) = 0.7*0.6 =\", 0.7*0.6)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "add4330c",
   "metadata": {},
   "source": [
    "2. yes getting decafe coffee and choosing to whether go to tims are independent events\n",
    "3. since decaf and locations are independent, the probability of being in Starbucks is 1-Probability(tims) = 1-0.7 = 0.3\n",
    "4. P(A U B) = P(A)+P(B) - P(A)*P(B); A is P(tims) , B is P(decaf) ; P(tims U decaf) = 0.7+0.6 - 0.42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdaa6a9",
   "metadata": {},
   "source": [
    "#### Problem 4E\n",
    "\n",
    "Suppose 5% of all students in a class are knowingly cheating on a test and another 2% inadvertently cheat because they were not familiar with the rules of excessive collaboration. Of the 5% who were guilty of knowingly cheating, 80% will deny the cheating allegation if confronted by their professor. If a student is confronted with a cheating allegation and they deny the allegation, what is the probability that they are guilty?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68289147",
   "metadata": {},
   "source": [
    "#### Problem 4E - Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c220a3a",
   "metadata": {},
   "source": [
    "Probability of simply guilty people:P(G) 5/7 (if we assume a 100 people, 5 knowingly cheated and 2 didn't know they did)\n",
    "\n",
    "80% of guilty students will deny, while hopefully 100% of non-guilty will deny\n",
    "\n",
    "Hence if we look for guilty given that they denied we can do the following\n",
    "$P(G|D) = P(G)*P(D|G)/(P(G)P(D|G)+(1-P(G))P(D|G'))$\n",
    "= $5/7*0.8/(5/7*0.8+2/7*1)$\n",
    "= 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bef720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64d014a6",
   "metadata": {},
   "source": [
    "#### Problem 4F\n",
    "\n",
    "Medical case histories indicate that different illnesses may produce identical symptoms. Let's say a particular set of symptoms, which we will denote as event $H$, occurs only when any of these three illnesses ($X, Y, Z$) occurs. Assume that the illnesses are mutually exclusive (ie. you can only be diagnosed with one illness at a time). Studies show that these are the probabilities of getting each illness:\n",
    "- $P(X) = 0.01$\n",
    "- $P(Y) = 0.005$\n",
    "- $P(Z) = 0.02$\n",
    "\n",
    "Meanwhile, the probabilities of developing the symptoms $H$, given a specific illness, are as follows:\n",
    "- $P(H|X) = 0.90$\n",
    "- $P(H|Y) = 0.95$\n",
    "- $P(H|Z) = 0.75$\n",
    "\n",
    "Assuming that an ill person shows the symptoms $H$, what is the probability that the person has illness $X$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d4fc3",
   "metadata": {},
   "source": [
    "#### Problem 4F - Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87471543",
   "metadata": {},
   "source": [
    "Using Baye's Theorem we can write\n",
    "P(X|H) = P(x)P(H|X)/(P(X)P(H|X)+P(Y)P(H|Y)+P(Z)P(H|Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ae9e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therefore the probability is 0.3130434782608696\n"
     ]
    }
   ],
   "source": [
    "print(\"Therefore the probability is\", 0.01*0.9/(0.01*0.9+0.005*0.95+0.02*0.75))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d88b7d5c6f842aec972d2bf3dc7634d8accd620febbbf6c17d17a97ce72770e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
